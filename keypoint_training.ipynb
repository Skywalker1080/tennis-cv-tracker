{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49fe30ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42efadd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34111773",
   "metadata": {},
   "source": [
    "Creating torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4c8e2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeypointsData(Dataset):\n",
    "    def __init__(self, img_dir, data_file):\n",
    "        self.img_dir = img_dir\n",
    "        with open(data_file, 'r') as f:\n",
    "            self.data = json.load(f)\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.458, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        img = cv2.imread(f\"{self.img_dir}/{item['id']}.png\")\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = self.transform(img)\n",
    "        kps = np.array(item['kps']).flatten()\n",
    "        kps = kps.astype(np.float32)\n",
    "\n",
    "        kps[::2] *= 224.0 / w\n",
    "        kps[1::2] *= 224.0 / h\n",
    "\n",
    "        return img, kps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "297dcf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = KeypointsData('data/images', 'data/data_train.json')\n",
    "val_dataset = KeypointsData('data/images', 'data/data_val.json')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_laoder = DataLoader(val_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd14bad",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51d61b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pranav Darekar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Pranav Darekar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 14*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1771651",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3fbb46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e32a25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, iter 0, loss: 14093.728515625\n",
      "Epoch 0, iter 10, loss: 13842.2802734375\n",
      "Epoch 0, iter 20, loss: 14974.134765625\n",
      "Epoch 0, iter 30, loss: 14217.041015625\n",
      "Epoch 0, iter 40, loss: 13785.353515625\n",
      "Epoch 0, iter 50, loss: 13268.5126953125\n",
      "Epoch 0, iter 60, loss: 12994.708984375\n",
      "Epoch 0, iter 70, loss: 12608.423828125\n",
      "Epoch 0, iter 80, loss: 12048.771484375\n",
      "Epoch 0, iter 90, loss: 11460.7275390625\n",
      "Epoch 0, iter 100, loss: 10889.919921875\n",
      "Epoch 0, iter 110, loss: 11093.5966796875\n",
      "Epoch 0, iter 120, loss: 10149.857421875\n",
      "Epoch 0, iter 130, loss: 10327.0849609375\n",
      "Epoch 0, iter 140, loss: 9541.8017578125\n",
      "Epoch 0, iter 150, loss: 9375.1318359375\n",
      "Epoch 0, iter 160, loss: 9354.798828125\n",
      "Epoch 0, iter 170, loss: 8353.9755859375\n",
      "Epoch 0, iter 180, loss: 8535.0302734375\n",
      "Epoch 0, iter 190, loss: 8429.05859375\n",
      "Epoch 0, iter 200, loss: 7977.33203125\n",
      "Epoch 0, iter 210, loss: 7687.47802734375\n",
      "Epoch 0, iter 220, loss: 7328.00048828125\n",
      "Epoch 0, iter 230, loss: 7635.16455078125\n",
      "Epoch 0, iter 240, loss: 6990.724609375\n",
      "Epoch 0, iter 250, loss: 6714.89990234375\n",
      "Epoch 0, iter 260, loss: 6055.04833984375\n",
      "Epoch 0, iter 270, loss: 5611.35498046875\n",
      "Epoch 0, iter 280, loss: 5365.984375\n",
      "Epoch 0, iter 290, loss: 5559.9208984375\n",
      "Epoch 0, iter 300, loss: 5117.54248046875\n",
      "Epoch 0, iter 310, loss: 5123.16259765625\n",
      "Epoch 0, iter 320, loss: 5217.80029296875\n",
      "Epoch 0, iter 330, loss: 4521.0751953125\n",
      "Epoch 0, iter 340, loss: 4806.21435546875\n",
      "Epoch 0, iter 350, loss: 4299.35302734375\n",
      "Epoch 0, iter 360, loss: 4304.2109375\n",
      "Epoch 0, iter 370, loss: 3611.1435546875\n",
      "Epoch 0, iter 380, loss: 4038.48681640625\n",
      "Epoch 0, iter 390, loss: 3591.52978515625\n",
      "Epoch 0, iter 400, loss: 3477.31982421875\n",
      "Epoch 0, iter 410, loss: 3234.89306640625\n",
      "Epoch 0, iter 420, loss: 2893.505615234375\n",
      "Epoch 0, iter 430, loss: 2890.134521484375\n",
      "Epoch 0, iter 440, loss: 2977.058837890625\n",
      "Epoch 0, iter 450, loss: 2659.774658203125\n",
      "Epoch 0, iter 460, loss: 2504.066162109375\n",
      "Epoch 0, iter 470, loss: 2311.3251953125\n",
      "Epoch 0, iter 480, loss: 2323.414794921875\n",
      "Epoch 0, iter 490, loss: 2054.67333984375\n",
      "Epoch 0, iter 500, loss: 2076.183349609375\n",
      "Epoch 0, iter 510, loss: 1989.5938720703125\n",
      "Epoch 0, iter 520, loss: 1915.1273193359375\n",
      "Epoch 0, iter 530, loss: 1931.6104736328125\n",
      "Epoch 0, iter 540, loss: 1916.773193359375\n",
      "Epoch 0, iter 550, loss: 1599.787841796875\n",
      "Epoch 0, iter 560, loss: 1405.91650390625\n",
      "Epoch 0, iter 570, loss: 1278.165283203125\n",
      "Epoch 0, iter 580, loss: 1323.572509765625\n",
      "Epoch 0, iter 590, loss: 961.387451171875\n",
      "Epoch 0, iter 600, loss: 1263.323486328125\n",
      "Epoch 0, iter 610, loss: 1231.18896484375\n",
      "Epoch 0, iter 620, loss: 901.560302734375\n",
      "Epoch 0, iter 630, loss: 1061.2191162109375\n",
      "Epoch 0, iter 640, loss: 840.5283813476562\n",
      "Epoch 0, iter 650, loss: 1025.0418701171875\n",
      "Epoch 0, iter 660, loss: 774.9828491210938\n",
      "Epoch 0, iter 670, loss: 789.2098999023438\n",
      "Epoch 0, iter 680, loss: 714.0142822265625\n",
      "Epoch 0, iter 690, loss: 661.2249145507812\n",
      "Epoch 0, iter 700, loss: 618.15625\n",
      "Epoch 0, iter 710, loss: 629.1053466796875\n",
      "Epoch 0, iter 720, loss: 570.318603515625\n",
      "Epoch 0, iter 730, loss: 435.5802307128906\n",
      "Epoch 0, iter 740, loss: 433.0393371582031\n",
      "Epoch 0, iter 750, loss: 420.8346862792969\n",
      "Epoch 0, iter 760, loss: 282.6171569824219\n",
      "Epoch 0, iter 770, loss: 314.91015625\n",
      "Epoch 0, iter 780, loss: 304.6047058105469\n",
      "Epoch 0, iter 790, loss: 341.4615173339844\n",
      "Epoch 0, iter 800, loss: 341.6232604980469\n",
      "Epoch 0, iter 810, loss: 301.5919189453125\n",
      "Epoch 0, iter 820, loss: 316.11700439453125\n",
      "Epoch 1, iter 0, loss: 283.7709045410156\n",
      "Epoch 1, iter 10, loss: 223.6704559326172\n",
      "Epoch 1, iter 20, loss: 221.7261505126953\n",
      "Epoch 1, iter 30, loss: 190.38522338867188\n",
      "Epoch 1, iter 40, loss: 305.2904052734375\n",
      "Epoch 1, iter 50, loss: 181.8035125732422\n",
      "Epoch 1, iter 60, loss: 190.21109008789062\n",
      "Epoch 1, iter 70, loss: 207.24624633789062\n",
      "Epoch 1, iter 80, loss: 680.81103515625\n",
      "Epoch 1, iter 90, loss: 139.610107421875\n",
      "Epoch 1, iter 100, loss: 126.09693145751953\n",
      "Epoch 1, iter 110, loss: 116.7563705444336\n",
      "Epoch 1, iter 120, loss: 119.11483764648438\n",
      "Epoch 1, iter 130, loss: 124.02322387695312\n",
      "Epoch 1, iter 140, loss: 75.8369140625\n",
      "Epoch 1, iter 150, loss: 373.4062805175781\n",
      "Epoch 1, iter 160, loss: 106.99129486083984\n",
      "Epoch 1, iter 170, loss: 241.7262420654297\n",
      "Epoch 1, iter 180, loss: 69.56090545654297\n",
      "Epoch 1, iter 190, loss: 156.7712860107422\n",
      "Epoch 1, iter 200, loss: 126.00651550292969\n",
      "Epoch 1, iter 210, loss: 133.70127868652344\n",
      "Epoch 1, iter 220, loss: 87.47393035888672\n",
      "Epoch 1, iter 230, loss: 105.89707946777344\n",
      "Epoch 1, iter 240, loss: 58.820377349853516\n",
      "Epoch 1, iter 250, loss: 68.78652954101562\n",
      "Epoch 1, iter 260, loss: 52.31814956665039\n",
      "Epoch 1, iter 270, loss: 39.50741195678711\n",
      "Epoch 1, iter 280, loss: 28.953859329223633\n",
      "Epoch 1, iter 290, loss: 48.27814483642578\n",
      "Epoch 1, iter 300, loss: 54.231666564941406\n",
      "Epoch 1, iter 310, loss: 90.18692779541016\n",
      "Epoch 1, iter 320, loss: 86.16097259521484\n",
      "Epoch 1, iter 330, loss: 41.49701690673828\n",
      "Epoch 1, iter 340, loss: 52.648292541503906\n",
      "Epoch 1, iter 350, loss: 26.262243270874023\n",
      "Epoch 1, iter 360, loss: 21.5565242767334\n",
      "Epoch 1, iter 370, loss: 46.08375930786133\n",
      "Epoch 1, iter 380, loss: 30.589509963989258\n",
      "Epoch 1, iter 390, loss: 69.54489135742188\n",
      "Epoch 1, iter 400, loss: 56.473907470703125\n",
      "Epoch 1, iter 410, loss: 55.43287658691406\n",
      "Epoch 1, iter 420, loss: 48.10118865966797\n",
      "Epoch 1, iter 430, loss: 57.88046646118164\n",
      "Epoch 1, iter 440, loss: 48.34571075439453\n",
      "Epoch 1, iter 450, loss: 219.96766662597656\n",
      "Epoch 1, iter 460, loss: 32.20093536376953\n",
      "Epoch 1, iter 470, loss: 52.57115173339844\n",
      "Epoch 1, iter 480, loss: 30.317039489746094\n",
      "Epoch 1, iter 490, loss: 72.87064361572266\n",
      "Epoch 1, iter 500, loss: 46.889366149902344\n",
      "Epoch 1, iter 510, loss: 97.3950424194336\n",
      "Epoch 1, iter 520, loss: 51.023048400878906\n",
      "Epoch 1, iter 530, loss: 66.9213638305664\n",
      "Epoch 1, iter 540, loss: 62.47898864746094\n",
      "Epoch 1, iter 550, loss: 77.68876647949219\n",
      "Epoch 1, iter 560, loss: 37.61186218261719\n",
      "Epoch 1, iter 570, loss: 46.87873458862305\n",
      "Epoch 1, iter 580, loss: 28.16364288330078\n",
      "Epoch 1, iter 590, loss: 43.40178680419922\n",
      "Epoch 1, iter 600, loss: 46.25121307373047\n",
      "Epoch 1, iter 610, loss: 41.15132522583008\n",
      "Epoch 1, iter 620, loss: 67.6436767578125\n",
      "Epoch 1, iter 630, loss: 37.76021957397461\n",
      "Epoch 1, iter 640, loss: 18.04498291015625\n",
      "Epoch 1, iter 650, loss: 41.68981170654297\n",
      "Epoch 1, iter 660, loss: 16.814117431640625\n",
      "Epoch 1, iter 670, loss: 29.02560806274414\n",
      "Epoch 1, iter 680, loss: 58.87210464477539\n",
      "Epoch 1, iter 690, loss: 123.42657470703125\n",
      "Epoch 1, iter 700, loss: 21.992122650146484\n",
      "Epoch 1, iter 710, loss: 26.136714935302734\n",
      "Epoch 1, iter 720, loss: 619.8265380859375\n",
      "Epoch 1, iter 730, loss: 30.15184783935547\n",
      "Epoch 1, iter 740, loss: 42.1119499206543\n",
      "Epoch 1, iter 750, loss: 28.0568904876709\n",
      "Epoch 1, iter 760, loss: 24.674808502197266\n",
      "Epoch 1, iter 770, loss: 49.93635177612305\n",
      "Epoch 1, iter 780, loss: 64.24658203125\n",
      "Epoch 1, iter 790, loss: 23.934526443481445\n",
      "Epoch 1, iter 800, loss: 42.91950607299805\n",
      "Epoch 1, iter 810, loss: 41.2308235168457\n",
      "Epoch 1, iter 820, loss: 60.547821044921875\n",
      "Epoch 2, iter 0, loss: 44.79671096801758\n",
      "Epoch 2, iter 10, loss: 21.382680892944336\n",
      "Epoch 2, iter 20, loss: 41.03432083129883\n",
      "Epoch 2, iter 30, loss: 147.916748046875\n",
      "Epoch 2, iter 40, loss: 20.887958526611328\n",
      "Epoch 2, iter 50, loss: 37.21803665161133\n",
      "Epoch 2, iter 60, loss: 53.81105422973633\n",
      "Epoch 2, iter 70, loss: 47.05592346191406\n",
      "Epoch 2, iter 80, loss: 32.273773193359375\n",
      "Epoch 2, iter 90, loss: 43.23444747924805\n",
      "Epoch 2, iter 100, loss: 41.22441482543945\n",
      "Epoch 2, iter 110, loss: 33.459659576416016\n",
      "Epoch 2, iter 120, loss: 71.71465301513672\n",
      "Epoch 2, iter 130, loss: 27.251636505126953\n",
      "Epoch 2, iter 140, loss: 46.05202865600586\n",
      "Epoch 2, iter 150, loss: 24.804208755493164\n",
      "Epoch 2, iter 160, loss: 17.63666343688965\n",
      "Epoch 2, iter 170, loss: 48.68073654174805\n",
      "Epoch 2, iter 180, loss: 24.677595138549805\n",
      "Epoch 2, iter 190, loss: 22.932477951049805\n",
      "Epoch 2, iter 200, loss: 58.902530670166016\n",
      "Epoch 2, iter 210, loss: 30.489553451538086\n",
      "Epoch 2, iter 220, loss: 17.476455688476562\n",
      "Epoch 2, iter 230, loss: 66.54595947265625\n",
      "Epoch 2, iter 240, loss: 25.923648834228516\n",
      "Epoch 2, iter 250, loss: 13.942537307739258\n",
      "Epoch 2, iter 260, loss: 60.95143127441406\n",
      "Epoch 2, iter 270, loss: 24.31490707397461\n",
      "Epoch 2, iter 280, loss: 29.529232025146484\n",
      "Epoch 2, iter 290, loss: 16.046419143676758\n",
      "Epoch 2, iter 300, loss: 18.644954681396484\n",
      "Epoch 2, iter 310, loss: 24.206457138061523\n",
      "Epoch 2, iter 320, loss: 49.457645416259766\n",
      "Epoch 2, iter 330, loss: 18.21466064453125\n",
      "Epoch 2, iter 340, loss: 31.274269104003906\n",
      "Epoch 2, iter 350, loss: 86.68095397949219\n",
      "Epoch 2, iter 360, loss: 58.1268424987793\n",
      "Epoch 2, iter 370, loss: 39.14594268798828\n",
      "Epoch 2, iter 380, loss: 27.504467010498047\n",
      "Epoch 2, iter 390, loss: 23.294544219970703\n",
      "Epoch 2, iter 400, loss: 53.54615020751953\n",
      "Epoch 2, iter 410, loss: 31.68796730041504\n",
      "Epoch 2, iter 420, loss: 18.59873390197754\n",
      "Epoch 2, iter 430, loss: 38.88269805908203\n",
      "Epoch 2, iter 440, loss: 28.357248306274414\n",
      "Epoch 2, iter 450, loss: 82.77516174316406\n",
      "Epoch 2, iter 460, loss: 32.436004638671875\n",
      "Epoch 2, iter 470, loss: 48.511775970458984\n",
      "Epoch 2, iter 480, loss: 14.757615089416504\n",
      "Epoch 2, iter 490, loss: 13.557737350463867\n",
      "Epoch 2, iter 500, loss: 50.99728012084961\n",
      "Epoch 2, iter 510, loss: 40.7174186706543\n",
      "Epoch 2, iter 520, loss: 71.96465301513672\n",
      "Epoch 2, iter 530, loss: 13.587973594665527\n",
      "Epoch 2, iter 540, loss: 198.46743774414062\n",
      "Epoch 2, iter 550, loss: 16.477310180664062\n",
      "Epoch 2, iter 560, loss: 19.129159927368164\n",
      "Epoch 2, iter 570, loss: 65.6119384765625\n",
      "Epoch 2, iter 580, loss: 48.71904373168945\n",
      "Epoch 2, iter 590, loss: 17.193115234375\n",
      "Epoch 2, iter 600, loss: 18.724924087524414\n",
      "Epoch 2, iter 610, loss: 53.98003387451172\n",
      "Epoch 2, iter 620, loss: 21.595346450805664\n",
      "Epoch 2, iter 630, loss: 19.675397872924805\n",
      "Epoch 2, iter 640, loss: 66.84892272949219\n",
      "Epoch 2, iter 650, loss: 14.61202335357666\n",
      "Epoch 2, iter 660, loss: 13.148411750793457\n",
      "Epoch 2, iter 670, loss: 41.538360595703125\n",
      "Epoch 2, iter 680, loss: 22.640159606933594\n",
      "Epoch 2, iter 690, loss: 12.211651802062988\n",
      "Epoch 2, iter 700, loss: 59.16242599487305\n",
      "Epoch 2, iter 710, loss: 46.02391815185547\n",
      "Epoch 2, iter 720, loss: 24.481239318847656\n",
      "Epoch 2, iter 730, loss: 30.678529739379883\n",
      "Epoch 2, iter 740, loss: 25.614755630493164\n",
      "Epoch 2, iter 750, loss: 59.59750747680664\n",
      "Epoch 2, iter 760, loss: 30.545610427856445\n",
      "Epoch 2, iter 770, loss: 25.907262802124023\n",
      "Epoch 2, iter 780, loss: 29.758403778076172\n",
      "Epoch 2, iter 790, loss: 15.666692733764648\n",
      "Epoch 2, iter 800, loss: 13.045613288879395\n",
      "Epoch 2, iter 810, loss: 14.089777946472168\n",
      "Epoch 2, iter 820, loss: 26.422840118408203\n",
      "Epoch 3, iter 0, loss: 58.26380920410156\n",
      "Epoch 3, iter 10, loss: 18.834470748901367\n",
      "Epoch 3, iter 20, loss: 32.5970344543457\n",
      "Epoch 3, iter 30, loss: 11.30388355255127\n",
      "Epoch 3, iter 40, loss: 19.300323486328125\n",
      "Epoch 3, iter 50, loss: 31.961570739746094\n",
      "Epoch 3, iter 60, loss: 23.712146759033203\n",
      "Epoch 3, iter 70, loss: 21.44718360900879\n",
      "Epoch 3, iter 80, loss: 80.88753509521484\n",
      "Epoch 3, iter 90, loss: 28.096214294433594\n",
      "Epoch 3, iter 100, loss: 15.609156608581543\n",
      "Epoch 3, iter 110, loss: 25.331302642822266\n",
      "Epoch 3, iter 120, loss: 22.223560333251953\n",
      "Epoch 3, iter 130, loss: 25.707691192626953\n",
      "Epoch 3, iter 140, loss: 15.002037048339844\n",
      "Epoch 3, iter 150, loss: 7.658825874328613\n",
      "Epoch 3, iter 160, loss: 13.587985038757324\n",
      "Epoch 3, iter 170, loss: 29.1247615814209\n",
      "Epoch 3, iter 180, loss: 37.889339447021484\n",
      "Epoch 3, iter 190, loss: 176.8756561279297\n",
      "Epoch 3, iter 200, loss: 9.773468017578125\n",
      "Epoch 3, iter 210, loss: 26.873754501342773\n",
      "Epoch 3, iter 220, loss: 17.174718856811523\n",
      "Epoch 3, iter 230, loss: 9.195841789245605\n",
      "Epoch 3, iter 240, loss: 20.871835708618164\n",
      "Epoch 3, iter 250, loss: 33.021202087402344\n",
      "Epoch 3, iter 260, loss: 26.450977325439453\n",
      "Epoch 3, iter 270, loss: 17.305164337158203\n",
      "Epoch 3, iter 280, loss: 13.787775993347168\n",
      "Epoch 3, iter 290, loss: 62.26374435424805\n",
      "Epoch 3, iter 300, loss: 19.669815063476562\n",
      "Epoch 3, iter 310, loss: 43.15077209472656\n",
      "Epoch 3, iter 320, loss: 18.237163543701172\n",
      "Epoch 3, iter 330, loss: 26.78911590576172\n",
      "Epoch 3, iter 340, loss: 14.345431327819824\n",
      "Epoch 3, iter 350, loss: 24.53822898864746\n",
      "Epoch 3, iter 360, loss: 36.93895721435547\n",
      "Epoch 3, iter 370, loss: 16.950641632080078\n",
      "Epoch 3, iter 380, loss: 24.84785270690918\n",
      "Epoch 3, iter 390, loss: 19.217376708984375\n",
      "Epoch 3, iter 400, loss: 11.693361282348633\n",
      "Epoch 3, iter 410, loss: 20.2869815826416\n",
      "Epoch 3, iter 420, loss: 14.336282730102539\n",
      "Epoch 3, iter 430, loss: 12.80341911315918\n",
      "Epoch 3, iter 440, loss: 90.31495666503906\n",
      "Epoch 3, iter 450, loss: 102.51792907714844\n",
      "Epoch 3, iter 460, loss: 26.347389221191406\n",
      "Epoch 3, iter 470, loss: 28.862197875976562\n",
      "Epoch 3, iter 480, loss: 17.617258071899414\n",
      "Epoch 3, iter 490, loss: 16.963415145874023\n",
      "Epoch 3, iter 500, loss: 17.073129653930664\n",
      "Epoch 3, iter 510, loss: 28.196239471435547\n",
      "Epoch 3, iter 520, loss: 11.115918159484863\n",
      "Epoch 3, iter 530, loss: 21.615673065185547\n",
      "Epoch 3, iter 540, loss: 15.398849487304688\n",
      "Epoch 3, iter 550, loss: 20.538818359375\n",
      "Epoch 3, iter 560, loss: 14.283012390136719\n",
      "Epoch 3, iter 570, loss: 48.4746208190918\n",
      "Epoch 3, iter 580, loss: 10.700815200805664\n",
      "Epoch 3, iter 590, loss: 26.93657684326172\n",
      "Epoch 3, iter 600, loss: 32.04991912841797\n",
      "Epoch 3, iter 610, loss: 18.708148956298828\n",
      "Epoch 3, iter 620, loss: 22.636314392089844\n",
      "Epoch 3, iter 630, loss: 18.110164642333984\n",
      "Epoch 3, iter 640, loss: 25.11536407470703\n",
      "Epoch 3, iter 650, loss: 29.583240509033203\n",
      "Epoch 3, iter 660, loss: 39.382747650146484\n",
      "Epoch 3, iter 670, loss: 16.053157806396484\n",
      "Epoch 3, iter 680, loss: 13.866727828979492\n",
      "Epoch 3, iter 690, loss: 12.660252571105957\n",
      "Epoch 3, iter 700, loss: 7.706547737121582\n",
      "Epoch 3, iter 710, loss: 10.328414916992188\n",
      "Epoch 3, iter 720, loss: 10.950315475463867\n",
      "Epoch 3, iter 730, loss: 8.27637767791748\n",
      "Epoch 3, iter 740, loss: 5.698378562927246\n",
      "Epoch 3, iter 750, loss: 9.175041198730469\n",
      "Epoch 3, iter 760, loss: 19.346200942993164\n",
      "Epoch 3, iter 770, loss: 28.884479522705078\n",
      "Epoch 3, iter 780, loss: 147.6195526123047\n",
      "Epoch 3, iter 790, loss: 18.383115768432617\n",
      "Epoch 3, iter 800, loss: 8.075129508972168\n",
      "Epoch 3, iter 810, loss: 18.478004455566406\n",
      "Epoch 3, iter 820, loss: 36.24703598022461\n",
      "Epoch 4, iter 0, loss: 42.06573486328125\n",
      "Epoch 4, iter 10, loss: 10.561311721801758\n",
      "Epoch 4, iter 20, loss: 9.623807907104492\n",
      "Epoch 4, iter 30, loss: 5.961310386657715\n",
      "Epoch 4, iter 40, loss: 19.641523361206055\n",
      "Epoch 4, iter 50, loss: 30.766860961914062\n",
      "Epoch 4, iter 60, loss: 11.416373252868652\n",
      "Epoch 4, iter 70, loss: 11.015625953674316\n",
      "Epoch 4, iter 80, loss: 12.792557716369629\n",
      "Epoch 4, iter 90, loss: 32.03437805175781\n",
      "Epoch 4, iter 100, loss: 11.634363174438477\n",
      "Epoch 4, iter 110, loss: 14.6444673538208\n",
      "Epoch 4, iter 120, loss: 20.37052345275879\n",
      "Epoch 4, iter 130, loss: 13.023444175720215\n",
      "Epoch 4, iter 140, loss: 66.66679382324219\n",
      "Epoch 4, iter 150, loss: 14.25256633758545\n",
      "Epoch 4, iter 160, loss: 9.753108978271484\n",
      "Epoch 4, iter 170, loss: 9.923635482788086\n",
      "Epoch 4, iter 180, loss: 46.95276641845703\n",
      "Epoch 4, iter 190, loss: 16.1120662689209\n",
      "Epoch 4, iter 200, loss: 8.187207221984863\n",
      "Epoch 4, iter 210, loss: 8.03201961517334\n",
      "Epoch 4, iter 220, loss: 19.563655853271484\n",
      "Epoch 4, iter 230, loss: 8.9118013381958\n",
      "Epoch 4, iter 240, loss: 8.050765037536621\n",
      "Epoch 4, iter 250, loss: 14.399121284484863\n",
      "Epoch 4, iter 260, loss: 29.694625854492188\n",
      "Epoch 4, iter 270, loss: 11.035658836364746\n",
      "Epoch 4, iter 280, loss: 8.33686351776123\n",
      "Epoch 4, iter 290, loss: 2.536074161529541\n",
      "Epoch 4, iter 300, loss: 9.724736213684082\n",
      "Epoch 4, iter 310, loss: 30.006473541259766\n",
      "Epoch 4, iter 320, loss: 24.129621505737305\n",
      "Epoch 4, iter 330, loss: 19.101781845092773\n",
      "Epoch 4, iter 340, loss: 17.57201385498047\n",
      "Epoch 4, iter 350, loss: 43.897499084472656\n",
      "Epoch 4, iter 360, loss: 12.646662712097168\n",
      "Epoch 4, iter 370, loss: 9.742822647094727\n",
      "Epoch 4, iter 380, loss: 9.563056945800781\n",
      "Epoch 4, iter 390, loss: 5.733542442321777\n",
      "Epoch 4, iter 400, loss: 16.983989715576172\n",
      "Epoch 4, iter 410, loss: 14.631447792053223\n",
      "Epoch 4, iter 420, loss: 29.102798461914062\n",
      "Epoch 4, iter 430, loss: 13.44913101196289\n",
      "Epoch 4, iter 440, loss: 14.054960250854492\n",
      "Epoch 4, iter 450, loss: 12.213136672973633\n",
      "Epoch 4, iter 460, loss: 15.308976173400879\n",
      "Epoch 4, iter 470, loss: 4.167556285858154\n",
      "Epoch 4, iter 480, loss: 23.89376449584961\n",
      "Epoch 4, iter 490, loss: 82.67313385009766\n",
      "Epoch 4, iter 500, loss: 12.434958457946777\n",
      "Epoch 4, iter 510, loss: 10.342883110046387\n",
      "Epoch 4, iter 520, loss: 20.214378356933594\n",
      "Epoch 4, iter 530, loss: 15.393153190612793\n",
      "Epoch 4, iter 540, loss: 3.4530832767486572\n",
      "Epoch 4, iter 550, loss: 3.6486172676086426\n",
      "Epoch 4, iter 560, loss: 4.623347759246826\n",
      "Epoch 4, iter 570, loss: 5.70533561706543\n",
      "Epoch 4, iter 580, loss: 8.083343505859375\n",
      "Epoch 4, iter 590, loss: 21.55229949951172\n",
      "Epoch 4, iter 600, loss: 8.07172966003418\n",
      "Epoch 4, iter 610, loss: 7.3858642578125\n",
      "Epoch 4, iter 620, loss: 408.1047058105469\n",
      "Epoch 4, iter 630, loss: 24.86757469177246\n",
      "Epoch 4, iter 640, loss: 5.541379928588867\n",
      "Epoch 4, iter 650, loss: 24.213550567626953\n",
      "Epoch 4, iter 660, loss: 4.797886848449707\n",
      "Epoch 4, iter 670, loss: 27.847253799438477\n",
      "Epoch 4, iter 680, loss: 14.300618171691895\n",
      "Epoch 4, iter 690, loss: 31.94927215576172\n",
      "Epoch 4, iter 700, loss: 6.710237503051758\n",
      "Epoch 4, iter 710, loss: 27.776994705200195\n",
      "Epoch 4, iter 720, loss: 5.868555545806885\n",
      "Epoch 4, iter 730, loss: 14.398134231567383\n",
      "Epoch 4, iter 740, loss: 10.375778198242188\n",
      "Epoch 4, iter 750, loss: 7.8837409019470215\n",
      "Epoch 4, iter 760, loss: 8.213854789733887\n",
      "Epoch 4, iter 770, loss: 5.023256778717041\n",
      "Epoch 4, iter 780, loss: 12.070778846740723\n",
      "Epoch 4, iter 790, loss: 8.148618698120117\n",
      "Epoch 4, iter 800, loss: 16.1163330078125\n",
      "Epoch 4, iter 810, loss: 14.127817153930664\n",
      "Epoch 4, iter 820, loss: 5.600886344909668\n",
      "Epoch 5, iter 0, loss: 7.330162525177002\n",
      "Epoch 5, iter 10, loss: 6.530591011047363\n",
      "Epoch 5, iter 20, loss: 61.22846984863281\n",
      "Epoch 5, iter 30, loss: 11.005824089050293\n",
      "Epoch 5, iter 40, loss: 4.2533721923828125\n",
      "Epoch 5, iter 50, loss: 15.560968399047852\n",
      "Epoch 5, iter 60, loss: 4.029199600219727\n",
      "Epoch 5, iter 70, loss: 122.0331802368164\n",
      "Epoch 5, iter 80, loss: 5.7168660163879395\n",
      "Epoch 5, iter 90, loss: 4.458704948425293\n",
      "Epoch 5, iter 100, loss: 6.431530952453613\n",
      "Epoch 5, iter 110, loss: 8.844844818115234\n",
      "Epoch 5, iter 120, loss: 4.413698673248291\n",
      "Epoch 5, iter 130, loss: 14.422739028930664\n",
      "Epoch 5, iter 140, loss: 5.623568058013916\n",
      "Epoch 5, iter 150, loss: 5.824101448059082\n",
      "Epoch 5, iter 160, loss: 6.199939250946045\n",
      "Epoch 5, iter 170, loss: 5.915908336639404\n",
      "Epoch 5, iter 180, loss: 4.394775390625\n",
      "Epoch 5, iter 190, loss: 17.92681884765625\n",
      "Epoch 5, iter 200, loss: 8.026228904724121\n",
      "Epoch 5, iter 210, loss: 6.507509231567383\n",
      "Epoch 5, iter 220, loss: 8.179244041442871\n",
      "Epoch 5, iter 230, loss: 9.49188232421875\n",
      "Epoch 5, iter 240, loss: 13.180474281311035\n",
      "Epoch 5, iter 250, loss: 6.654593467712402\n",
      "Epoch 5, iter 260, loss: 14.562607765197754\n",
      "Epoch 5, iter 270, loss: 5.771810531616211\n",
      "Epoch 5, iter 280, loss: 27.103954315185547\n",
      "Epoch 5, iter 290, loss: 10.766855239868164\n",
      "Epoch 5, iter 300, loss: 4.85659646987915\n",
      "Epoch 5, iter 310, loss: 40.15510177612305\n",
      "Epoch 5, iter 320, loss: 6.725295066833496\n",
      "Epoch 5, iter 330, loss: 11.421248435974121\n",
      "Epoch 5, iter 340, loss: 14.895027160644531\n",
      "Epoch 5, iter 350, loss: 7.150358200073242\n",
      "Epoch 5, iter 360, loss: 10.007037162780762\n",
      "Epoch 5, iter 370, loss: 8.985777854919434\n",
      "Epoch 5, iter 380, loss: 5.046459197998047\n",
      "Epoch 5, iter 390, loss: 3.936155319213867\n",
      "Epoch 5, iter 400, loss: 13.132134437561035\n",
      "Epoch 5, iter 410, loss: 11.830830574035645\n",
      "Epoch 5, iter 420, loss: 7.171934127807617\n",
      "Epoch 5, iter 430, loss: 9.24046802520752\n",
      "Epoch 5, iter 440, loss: 12.971957206726074\n",
      "Epoch 5, iter 450, loss: 9.517902374267578\n",
      "Epoch 5, iter 460, loss: 9.40788459777832\n",
      "Epoch 5, iter 470, loss: 16.6090145111084\n",
      "Epoch 5, iter 480, loss: 3.9153010845184326\n",
      "Epoch 5, iter 490, loss: 3.968053102493286\n",
      "Epoch 5, iter 500, loss: 5.52841329574585\n",
      "Epoch 5, iter 510, loss: 5.183648109436035\n",
      "Epoch 5, iter 520, loss: 174.68161010742188\n",
      "Epoch 5, iter 530, loss: 10.589434623718262\n",
      "Epoch 5, iter 540, loss: 6.780366897583008\n",
      "Epoch 5, iter 550, loss: 2.8845179080963135\n",
      "Epoch 5, iter 560, loss: 4.166970252990723\n",
      "Epoch 5, iter 570, loss: 37.436988830566406\n",
      "Epoch 5, iter 580, loss: 8.519824981689453\n",
      "Epoch 5, iter 590, loss: 3.3080646991729736\n",
      "Epoch 5, iter 600, loss: 1.250955581665039\n",
      "Epoch 5, iter 610, loss: 26.888277053833008\n",
      "Epoch 5, iter 620, loss: 4.6805596351623535\n",
      "Epoch 5, iter 630, loss: 5.612460613250732\n",
      "Epoch 5, iter 640, loss: 6.527212619781494\n",
      "Epoch 5, iter 650, loss: 8.150838851928711\n",
      "Epoch 5, iter 660, loss: 6.767499923706055\n",
      "Epoch 5, iter 670, loss: 4.614325523376465\n",
      "Epoch 5, iter 680, loss: 30.56417465209961\n",
      "Epoch 5, iter 690, loss: 5.2485833168029785\n",
      "Epoch 5, iter 700, loss: 6.844254493713379\n",
      "Epoch 5, iter 710, loss: 6.020306587219238\n",
      "Epoch 5, iter 720, loss: 23.783937454223633\n",
      "Epoch 5, iter 730, loss: 3.911581039428711\n",
      "Epoch 5, iter 740, loss: 4.708230495452881\n",
      "Epoch 5, iter 750, loss: 6.940802574157715\n",
      "Epoch 5, iter 760, loss: 2.610638380050659\n",
      "Epoch 5, iter 770, loss: 7.975292205810547\n",
      "Epoch 5, iter 780, loss: 15.845926284790039\n",
      "Epoch 5, iter 790, loss: 24.715028762817383\n",
      "Epoch 5, iter 800, loss: 4.510415554046631\n",
      "Epoch 5, iter 810, loss: 9.292370796203613\n",
      "Epoch 5, iter 820, loss: 8.74348258972168\n",
      "Epoch 6, iter 0, loss: 5.570691108703613\n",
      "Epoch 6, iter 10, loss: 11.55440616607666\n",
      "Epoch 6, iter 20, loss: 6.92274284362793\n",
      "Epoch 6, iter 30, loss: 10.605106353759766\n",
      "Epoch 6, iter 40, loss: 5.167198181152344\n",
      "Epoch 6, iter 50, loss: 11.687219619750977\n",
      "Epoch 6, iter 60, loss: 4.11442756652832\n",
      "Epoch 6, iter 70, loss: 9.488080978393555\n",
      "Epoch 6, iter 80, loss: 3.487797975540161\n",
      "Epoch 6, iter 90, loss: 9.503493309020996\n",
      "Epoch 6, iter 100, loss: 3.1218504905700684\n",
      "Epoch 6, iter 110, loss: 55.73692321777344\n",
      "Epoch 6, iter 120, loss: 7.142846584320068\n",
      "Epoch 6, iter 130, loss: 3.7561123371124268\n",
      "Epoch 6, iter 140, loss: 5.143217086791992\n",
      "Epoch 6, iter 150, loss: 9.12844467163086\n",
      "Epoch 6, iter 160, loss: 5.012868881225586\n",
      "Epoch 6, iter 170, loss: 5.227677822113037\n",
      "Epoch 6, iter 180, loss: 3.0475900173187256\n",
      "Epoch 6, iter 190, loss: 6.072070598602295\n",
      "Epoch 6, iter 200, loss: 15.936094284057617\n",
      "Epoch 6, iter 210, loss: 4.221928596496582\n",
      "Epoch 6, iter 220, loss: 3.1309149265289307\n",
      "Epoch 6, iter 230, loss: 7.707379341125488\n",
      "Epoch 6, iter 240, loss: 10.565083503723145\n",
      "Epoch 6, iter 250, loss: 3.2923154830932617\n",
      "Epoch 6, iter 260, loss: 6.572909355163574\n",
      "Epoch 6, iter 270, loss: 3.6706371307373047\n",
      "Epoch 6, iter 280, loss: 6.989755153656006\n",
      "Epoch 6, iter 290, loss: 2.6694295406341553\n",
      "Epoch 6, iter 300, loss: 4.857675552368164\n",
      "Epoch 6, iter 310, loss: 3.4095733165740967\n",
      "Epoch 6, iter 320, loss: 11.153313636779785\n",
      "Epoch 6, iter 330, loss: 4.25181770324707\n",
      "Epoch 6, iter 340, loss: 19.843610763549805\n",
      "Epoch 6, iter 350, loss: 5.07333517074585\n",
      "Epoch 6, iter 360, loss: 2.5665245056152344\n",
      "Epoch 6, iter 370, loss: 2.915311336517334\n",
      "Epoch 6, iter 380, loss: 2.616981267929077\n",
      "Epoch 6, iter 390, loss: 4.415359973907471\n",
      "Epoch 6, iter 400, loss: 1.652489423751831\n",
      "Epoch 6, iter 410, loss: 6.038057804107666\n",
      "Epoch 6, iter 420, loss: 2.763523817062378\n",
      "Epoch 6, iter 430, loss: 3.5820505619049072\n",
      "Epoch 6, iter 440, loss: 5.807836532592773\n",
      "Epoch 6, iter 450, loss: 9.035748481750488\n",
      "Epoch 6, iter 460, loss: 3.0659303665161133\n",
      "Epoch 6, iter 470, loss: 10.079254150390625\n",
      "Epoch 6, iter 480, loss: 2.0993127822875977\n",
      "Epoch 6, iter 490, loss: 8.750200271606445\n",
      "Epoch 6, iter 500, loss: 151.6104736328125\n",
      "Epoch 6, iter 510, loss: 39.627052307128906\n",
      "Epoch 6, iter 520, loss: 5.689264297485352\n",
      "Epoch 6, iter 530, loss: 168.25372314453125\n",
      "Epoch 6, iter 540, loss: 16.52644157409668\n",
      "Epoch 6, iter 550, loss: 3.0162253379821777\n",
      "Epoch 6, iter 560, loss: 6.8250298500061035\n",
      "Epoch 6, iter 570, loss: 7.797098159790039\n",
      "Epoch 6, iter 580, loss: 7.295199394226074\n",
      "Epoch 6, iter 590, loss: 4.025105953216553\n",
      "Epoch 6, iter 600, loss: 2.5214059352874756\n",
      "Epoch 6, iter 610, loss: 84.88795471191406\n",
      "Epoch 6, iter 620, loss: 8.904444694519043\n",
      "Epoch 6, iter 630, loss: 4.056479454040527\n",
      "Epoch 6, iter 640, loss: 1.9867955446243286\n",
      "Epoch 6, iter 650, loss: 6.414771556854248\n",
      "Epoch 6, iter 660, loss: 2.1397817134857178\n",
      "Epoch 6, iter 670, loss: 112.48896026611328\n",
      "Epoch 6, iter 680, loss: 6.610284328460693\n",
      "Epoch 6, iter 690, loss: 3.445389986038208\n",
      "Epoch 6, iter 700, loss: 3.2565701007843018\n",
      "Epoch 6, iter 710, loss: 3.710782289505005\n",
      "Epoch 6, iter 720, loss: 9.942235946655273\n",
      "Epoch 6, iter 730, loss: 3.0661301612854004\n",
      "Epoch 6, iter 740, loss: 5.011104106903076\n",
      "Epoch 6, iter 750, loss: 300.6110534667969\n",
      "Epoch 6, iter 760, loss: 5.493465900421143\n",
      "Epoch 6, iter 770, loss: 7.728638648986816\n",
      "Epoch 6, iter 780, loss: 6.314441204071045\n",
      "Epoch 6, iter 790, loss: 3.4427237510681152\n",
      "Epoch 6, iter 800, loss: 12.878193855285645\n",
      "Epoch 6, iter 810, loss: 46.51049041748047\n",
      "Epoch 6, iter 820, loss: 32.23252868652344\n",
      "Epoch 7, iter 0, loss: 4.64302396774292\n",
      "Epoch 7, iter 10, loss: 10.246152877807617\n",
      "Epoch 7, iter 20, loss: 1.4883334636688232\n",
      "Epoch 7, iter 30, loss: 1.857923984527588\n",
      "Epoch 7, iter 40, loss: 6.884973049163818\n",
      "Epoch 7, iter 50, loss: 11.632418632507324\n",
      "Epoch 7, iter 60, loss: 4.696613311767578\n",
      "Epoch 7, iter 70, loss: 16.924211502075195\n",
      "Epoch 7, iter 80, loss: 4.800089359283447\n",
      "Epoch 7, iter 90, loss: 1.688787817955017\n",
      "Epoch 7, iter 100, loss: 9.062357902526855\n",
      "Epoch 7, iter 110, loss: 2.755444288253784\n",
      "Epoch 7, iter 120, loss: 2.215266227722168\n",
      "Epoch 7, iter 130, loss: 4.965848922729492\n",
      "Epoch 7, iter 140, loss: 6.656215190887451\n",
      "Epoch 7, iter 150, loss: 41.54990768432617\n",
      "Epoch 7, iter 160, loss: 14.572762489318848\n",
      "Epoch 7, iter 170, loss: 3.8060200214385986\n",
      "Epoch 7, iter 180, loss: 8.61032485961914\n",
      "Epoch 7, iter 190, loss: 132.52188110351562\n",
      "Epoch 7, iter 200, loss: 1.2499622106552124\n",
      "Epoch 7, iter 210, loss: 3.0163276195526123\n",
      "Epoch 7, iter 220, loss: 3.774454116821289\n",
      "Epoch 7, iter 230, loss: 3.706308364868164\n",
      "Epoch 7, iter 240, loss: 1.1402273178100586\n",
      "Epoch 7, iter 250, loss: 5.839539051055908\n",
      "Epoch 7, iter 260, loss: 5.482919216156006\n",
      "Epoch 7, iter 270, loss: 2.120476484298706\n",
      "Epoch 7, iter 280, loss: 6.855025291442871\n",
      "Epoch 7, iter 290, loss: 29.776161193847656\n",
      "Epoch 7, iter 300, loss: 5.66711950302124\n",
      "Epoch 7, iter 310, loss: 8.451276779174805\n",
      "Epoch 7, iter 320, loss: 6.538492679595947\n",
      "Epoch 7, iter 330, loss: 20.098743438720703\n",
      "Epoch 7, iter 340, loss: 2.1222004890441895\n",
      "Epoch 7, iter 350, loss: 3.1556217670440674\n",
      "Epoch 7, iter 360, loss: 4.821560859680176\n",
      "Epoch 7, iter 370, loss: 5.47352933883667\n",
      "Epoch 7, iter 380, loss: 8.330785751342773\n",
      "Epoch 7, iter 390, loss: 12.788951873779297\n",
      "Epoch 7, iter 400, loss: 2.8702001571655273\n",
      "Epoch 7, iter 410, loss: 7.420314788818359\n",
      "Epoch 7, iter 420, loss: 2.960146903991699\n",
      "Epoch 7, iter 430, loss: 3.668469190597534\n",
      "Epoch 7, iter 440, loss: 4.609759330749512\n",
      "Epoch 7, iter 450, loss: 1.6893998384475708\n",
      "Epoch 7, iter 460, loss: 2.347642183303833\n",
      "Epoch 7, iter 470, loss: 2.5098702907562256\n",
      "Epoch 7, iter 480, loss: 16.510887145996094\n",
      "Epoch 7, iter 490, loss: 14.920463562011719\n",
      "Epoch 7, iter 500, loss: 2.592216968536377\n",
      "Epoch 7, iter 510, loss: 2.2720274925231934\n",
      "Epoch 7, iter 520, loss: 5.463620185852051\n",
      "Epoch 7, iter 530, loss: 0.7564484477043152\n",
      "Epoch 7, iter 540, loss: 8.527568817138672\n",
      "Epoch 7, iter 550, loss: 6.896653652191162\n",
      "Epoch 7, iter 560, loss: 3.1644370555877686\n",
      "Epoch 7, iter 570, loss: 15.970743179321289\n",
      "Epoch 7, iter 580, loss: 0.7555423378944397\n",
      "Epoch 7, iter 590, loss: 2.7316184043884277\n",
      "Epoch 7, iter 600, loss: 15.797494888305664\n",
      "Epoch 7, iter 610, loss: 3.194791555404663\n",
      "Epoch 7, iter 620, loss: 7.686572074890137\n",
      "Epoch 7, iter 630, loss: 3.4043705463409424\n",
      "Epoch 7, iter 640, loss: 8.004196166992188\n",
      "Epoch 7, iter 650, loss: 4.768625736236572\n",
      "Epoch 7, iter 660, loss: 1.1716513633728027\n",
      "Epoch 7, iter 670, loss: 11.275815963745117\n",
      "Epoch 7, iter 680, loss: 16.650333404541016\n",
      "Epoch 7, iter 690, loss: 7.967105865478516\n",
      "Epoch 7, iter 700, loss: 0.7481079697608948\n",
      "Epoch 7, iter 710, loss: 1.9694569110870361\n",
      "Epoch 7, iter 720, loss: 6.04699182510376\n",
      "Epoch 7, iter 730, loss: 2.281064748764038\n",
      "Epoch 7, iter 740, loss: 9.169713020324707\n",
      "Epoch 7, iter 750, loss: 11.42794418334961\n",
      "Epoch 7, iter 760, loss: 3.269517660140991\n",
      "Epoch 7, iter 770, loss: 1.1169264316558838\n",
      "Epoch 7, iter 780, loss: 12.921357154846191\n",
      "Epoch 7, iter 790, loss: 15.988308906555176\n",
      "Epoch 7, iter 800, loss: 2.9673447608947754\n",
      "Epoch 7, iter 810, loss: 2.9176108837127686\n",
      "Epoch 7, iter 820, loss: 22.793981552124023\n",
      "Epoch 8, iter 0, loss: 2.699676752090454\n",
      "Epoch 8, iter 10, loss: 4.0951666831970215\n",
      "Epoch 8, iter 20, loss: 6.309561729431152\n",
      "Epoch 8, iter 30, loss: 3.149303674697876\n",
      "Epoch 8, iter 40, loss: 1.4672797918319702\n",
      "Epoch 8, iter 50, loss: 2.329003095626831\n",
      "Epoch 8, iter 60, loss: 12.733576774597168\n",
      "Epoch 8, iter 70, loss: 5.602229118347168\n",
      "Epoch 8, iter 80, loss: 2.5732007026672363\n",
      "Epoch 8, iter 90, loss: 6.774905681610107\n",
      "Epoch 8, iter 100, loss: 15.346585273742676\n",
      "Epoch 8, iter 110, loss: 7.16409969329834\n",
      "Epoch 8, iter 120, loss: 5.3690996170043945\n",
      "Epoch 8, iter 130, loss: 37.56282424926758\n",
      "Epoch 8, iter 140, loss: 3.3079097270965576\n",
      "Epoch 8, iter 150, loss: 11.849672317504883\n",
      "Epoch 8, iter 160, loss: 8.66396713256836\n",
      "Epoch 8, iter 170, loss: 5.088232040405273\n",
      "Epoch 8, iter 180, loss: 9.22744369506836\n",
      "Epoch 8, iter 190, loss: 8.174948692321777\n",
      "Epoch 8, iter 200, loss: 1.5178160667419434\n",
      "Epoch 8, iter 210, loss: 6.3013014793396\n",
      "Epoch 8, iter 220, loss: 3.0735344886779785\n",
      "Epoch 8, iter 230, loss: 1.0329818725585938\n",
      "Epoch 8, iter 240, loss: 0.8475667834281921\n",
      "Epoch 8, iter 250, loss: 5.058940410614014\n",
      "Epoch 8, iter 260, loss: 1.5853315591812134\n",
      "Epoch 8, iter 270, loss: 1.3061892986297607\n",
      "Epoch 8, iter 280, loss: 4.59026575088501\n",
      "Epoch 8, iter 290, loss: 1.8761259317398071\n",
      "Epoch 8, iter 300, loss: 2.943758487701416\n",
      "Epoch 8, iter 310, loss: 20.874826431274414\n",
      "Epoch 8, iter 320, loss: 3.97737979888916\n",
      "Epoch 8, iter 330, loss: 2.9274911880493164\n",
      "Epoch 8, iter 340, loss: 3.0768320560455322\n",
      "Epoch 8, iter 350, loss: 1.5225269794464111\n",
      "Epoch 8, iter 360, loss: 5.388005256652832\n",
      "Epoch 8, iter 370, loss: 14.967622756958008\n",
      "Epoch 8, iter 380, loss: 3.4327738285064697\n",
      "Epoch 8, iter 390, loss: 1.0007290840148926\n",
      "Epoch 8, iter 400, loss: 2.5875980854034424\n",
      "Epoch 8, iter 410, loss: 3.986638307571411\n",
      "Epoch 8, iter 420, loss: 3.748223066329956\n",
      "Epoch 8, iter 430, loss: 3.100386381149292\n",
      "Epoch 8, iter 440, loss: 0.5481131672859192\n",
      "Epoch 8, iter 450, loss: 3.2528421878814697\n",
      "Epoch 8, iter 460, loss: 1.156690001487732\n",
      "Epoch 8, iter 470, loss: 1.4962947368621826\n",
      "Epoch 8, iter 480, loss: 8.503315925598145\n",
      "Epoch 8, iter 490, loss: 3.445129632949829\n",
      "Epoch 8, iter 500, loss: 13.168734550476074\n",
      "Epoch 8, iter 510, loss: 13.160645484924316\n",
      "Epoch 8, iter 520, loss: 4.533512592315674\n",
      "Epoch 8, iter 530, loss: 1.551896333694458\n",
      "Epoch 8, iter 540, loss: 6.346323490142822\n",
      "Epoch 8, iter 550, loss: 4.289538860321045\n",
      "Epoch 8, iter 560, loss: 9.07872486114502\n",
      "Epoch 8, iter 570, loss: 6.716668605804443\n",
      "Epoch 8, iter 580, loss: 2.988675355911255\n",
      "Epoch 8, iter 590, loss: 9.390913963317871\n",
      "Epoch 8, iter 600, loss: 1.7293893098831177\n",
      "Epoch 8, iter 610, loss: 3.035140037536621\n",
      "Epoch 8, iter 620, loss: 5.008481979370117\n",
      "Epoch 8, iter 630, loss: 10.222248077392578\n",
      "Epoch 8, iter 640, loss: 3.2551095485687256\n",
      "Epoch 8, iter 650, loss: 11.27401351928711\n",
      "Epoch 8, iter 660, loss: 8.189386367797852\n",
      "Epoch 8, iter 670, loss: 3.2658605575561523\n",
      "Epoch 8, iter 680, loss: 5.395633220672607\n",
      "Epoch 8, iter 690, loss: 5.527128219604492\n",
      "Epoch 8, iter 700, loss: 8.965835571289062\n",
      "Epoch 8, iter 710, loss: 3.977337121963501\n",
      "Epoch 8, iter 720, loss: 8.875707626342773\n",
      "Epoch 8, iter 730, loss: 2.6257073879241943\n",
      "Epoch 8, iter 740, loss: 2.259091854095459\n",
      "Epoch 8, iter 750, loss: 7.332892417907715\n",
      "Epoch 8, iter 760, loss: 3.609142541885376\n",
      "Epoch 8, iter 770, loss: 2.4076180458068848\n",
      "Epoch 8, iter 780, loss: 2.2489869594573975\n",
      "Epoch 8, iter 790, loss: 1.7535831928253174\n",
      "Epoch 8, iter 800, loss: 2.22515869140625\n",
      "Epoch 8, iter 810, loss: 2.49542498588562\n",
      "Epoch 8, iter 820, loss: 5.381973743438721\n",
      "Epoch 9, iter 0, loss: 8.65323543548584\n",
      "Epoch 9, iter 10, loss: 14.9606294631958\n",
      "Epoch 9, iter 20, loss: 10.20442008972168\n",
      "Epoch 9, iter 30, loss: 18.593059539794922\n",
      "Epoch 9, iter 40, loss: 1.965497612953186\n",
      "Epoch 9, iter 50, loss: 4.600423336029053\n",
      "Epoch 9, iter 60, loss: 1.2074573040008545\n",
      "Epoch 9, iter 70, loss: 4.935040473937988\n",
      "Epoch 9, iter 80, loss: 10.988862991333008\n",
      "Epoch 9, iter 90, loss: 9.42752742767334\n",
      "Epoch 9, iter 100, loss: 2.0285260677337646\n",
      "Epoch 9, iter 110, loss: 6.66875696182251\n",
      "Epoch 9, iter 120, loss: 1.222452163696289\n",
      "Epoch 9, iter 130, loss: 4.89316463470459\n",
      "Epoch 9, iter 140, loss: 4.941651344299316\n",
      "Epoch 9, iter 150, loss: 4.492579460144043\n",
      "Epoch 9, iter 160, loss: 2.3193612098693848\n",
      "Epoch 9, iter 170, loss: 1.6457411050796509\n",
      "Epoch 9, iter 180, loss: 6.656309127807617\n",
      "Epoch 9, iter 190, loss: 2.0149707794189453\n",
      "Epoch 9, iter 200, loss: 4.132689952850342\n",
      "Epoch 9, iter 210, loss: 4.860246181488037\n",
      "Epoch 9, iter 220, loss: 3.731013059616089\n",
      "Epoch 9, iter 230, loss: 2.371962070465088\n",
      "Epoch 9, iter 240, loss: 3.8920936584472656\n",
      "Epoch 9, iter 250, loss: 11.325502395629883\n",
      "Epoch 9, iter 260, loss: 2.628467082977295\n",
      "Epoch 9, iter 270, loss: 1.1653735637664795\n",
      "Epoch 9, iter 280, loss: 3.572645425796509\n",
      "Epoch 9, iter 290, loss: 7.904648780822754\n",
      "Epoch 9, iter 300, loss: 2.4432358741760254\n",
      "Epoch 9, iter 310, loss: 3.3608663082122803\n",
      "Epoch 9, iter 320, loss: 5.617697715759277\n",
      "Epoch 9, iter 330, loss: 3.6262617111206055\n",
      "Epoch 9, iter 340, loss: 14.649070739746094\n",
      "Epoch 9, iter 350, loss: 1.4477006196975708\n",
      "Epoch 9, iter 360, loss: 2.795189142227173\n",
      "Epoch 9, iter 370, loss: 1.3469494581222534\n",
      "Epoch 9, iter 380, loss: 3.274724245071411\n",
      "Epoch 9, iter 390, loss: 2.6328094005584717\n",
      "Epoch 9, iter 400, loss: 1.7646452188491821\n",
      "Epoch 9, iter 410, loss: 9.191134452819824\n",
      "Epoch 9, iter 420, loss: 77.46455383300781\n",
      "Epoch 9, iter 430, loss: 7.768473148345947\n",
      "Epoch 9, iter 440, loss: 0.9155276417732239\n",
      "Epoch 9, iter 450, loss: 5.732888221740723\n",
      "Epoch 9, iter 460, loss: 3.723588228225708\n",
      "Epoch 9, iter 470, loss: 1.9902902841567993\n",
      "Epoch 9, iter 480, loss: 3.6220099925994873\n",
      "Epoch 9, iter 490, loss: 2.8914921283721924\n",
      "Epoch 9, iter 500, loss: 2.019418716430664\n",
      "Epoch 9, iter 510, loss: 3.548830032348633\n",
      "Epoch 9, iter 520, loss: 3.263460397720337\n",
      "Epoch 9, iter 530, loss: 9.316609382629395\n",
      "Epoch 9, iter 540, loss: 9.776481628417969\n",
      "Epoch 9, iter 550, loss: 3.8841593265533447\n",
      "Epoch 9, iter 560, loss: 3.544973850250244\n",
      "Epoch 9, iter 570, loss: 4.887269020080566\n",
      "Epoch 9, iter 580, loss: 3.5104548931121826\n",
      "Epoch 9, iter 590, loss: 3.730562210083008\n",
      "Epoch 9, iter 600, loss: 4.02535343170166\n",
      "Epoch 9, iter 610, loss: 1.4745453596115112\n",
      "Epoch 9, iter 620, loss: 1.7432044744491577\n",
      "Epoch 9, iter 630, loss: 7.365907669067383\n",
      "Epoch 9, iter 640, loss: 2.434314727783203\n",
      "Epoch 9, iter 650, loss: 5.00244140625\n",
      "Epoch 9, iter 660, loss: 3.3510701656341553\n",
      "Epoch 9, iter 670, loss: 3.832942247390747\n",
      "Epoch 9, iter 680, loss: 7.374991416931152\n",
      "Epoch 9, iter 690, loss: 6.026636600494385\n",
      "Epoch 9, iter 700, loss: 2.9926984310150146\n",
      "Epoch 9, iter 710, loss: 2.8170363903045654\n",
      "Epoch 9, iter 720, loss: 0.37307408452033997\n",
      "Epoch 9, iter 730, loss: 1.1675693988800049\n",
      "Epoch 9, iter 740, loss: 1.9384853839874268\n",
      "Epoch 9, iter 750, loss: 2.0691440105438232\n",
      "Epoch 9, iter 760, loss: 2.5527591705322266\n",
      "Epoch 9, iter 770, loss: 4.690451145172119\n",
      "Epoch 9, iter 780, loss: 0.6411678194999695\n",
      "Epoch 9, iter 790, loss: 2.8139214515686035\n",
      "Epoch 9, iter 800, loss: 74.11094665527344\n",
      "Epoch 9, iter 810, loss: 5.019975185394287\n",
      "Epoch 9, iter 820, loss: 6.34697151184082\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for i, (imgs, kps) in enumerate(train_loader):\n",
    "        imgs = imgs.to(device)\n",
    "        kps = kps.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, kps)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%10 == 0:\n",
    "            print(f\"Epoch {epoch}, iter {i}, loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60333e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"keypoint_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4910e77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val MSE per coordinate:      12.2960\n",
      "Val RMSE per coordinate:     3.51 pixels\n",
      "Mean Euclidean error:        2.94 pixels\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "\n",
    "# 1) Device & model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet50(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 14*2)\n",
    "model.load_state_dict(torch.load('models/keypoints_model.pth', map_location='cpu'))\n",
    "model.to(device).eval()\n",
    "\n",
    "# 2) Val loader\n",
    "val_ds = KeypointsData('data/images', 'data/data_val.json')\n",
    "val_loader = DataLoader(val_ds, batch_size=16, shuffle=False)\n",
    "\n",
    "mse_criterion = torch.nn.MSELoss(reduction='sum')\n",
    "total_se = 0.0       # sum of squared errors\n",
    "total_coords = 0     # number of coordinate predictions\n",
    "all_euc = []         # to accumulate euclidean errors per keypoint\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, gt_kps in val_loader:\n",
    "        imgs    = imgs.to(device)\n",
    "        gt_kps  = gt_kps.to(device)   # shape [B, 28]\n",
    "\n",
    "        pred_kps = model(imgs)        # [B, 28]\n",
    "\n",
    "        # --- MSE ---\n",
    "        se = mse_criterion(pred_kps, gt_kps).item()\n",
    "        total_se    += se\n",
    "        total_coords += gt_kps.numel()\n",
    "\n",
    "        # --- Euclidean per-keypoint ---\n",
    "        pk = pred_kps.cpu().numpy().reshape(-1, 14, 2)\n",
    "        gk = gt_kps   .cpu().numpy().reshape(-1, 14, 2)\n",
    "        euc = np.linalg.norm(pk - gk, axis=2)  # [B, 14]\n",
    "        all_euc.append(euc)\n",
    "\n",
    "# Compute metrics\n",
    "mse  = total_se / total_coords\n",
    "rmse = np.sqrt(mse)\n",
    "mean_euc = np.vstack(all_euc).mean()\n",
    "\n",
    "print(f\"Val MSE per coordinate:      {mse:.4f}\")\n",
    "print(f\"Val RMSE per coordinate:     {rmse:.2f} pixels\")\n",
    "print(f\"Mean Euclidean error:        {mean_euc:.2f} pixels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08932183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KP 0: 3.37 px\n",
      "KP 1: 3.98 px\n",
      "KP 2: 3.42 px\n",
      "KP 3: 3.52 px\n",
      "KP 4: 3.06 px\n",
      "KP 5: 3.17 px\n",
      "KP 6: 3.56 px\n",
      "KP 7: 3.21 px\n",
      "KP 8: 2.67 px\n",
      "KP 9: 3.12 px\n",
      "KP10: 1.76 px\n",
      "KP11: 2.22 px\n",
      "KP12: 2.31 px\n",
      "KP13: 1.74 px\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming you still have `all_euc` from your validation loop:\n",
    "# all_euc is a list of arrays, each [batch_size, 14]\n",
    "errors = np.vstack(all_euc)   # shape [N_images  B, 14]\n",
    "\n",
    "mean_per_kp = errors.mean(axis=0)   # one mean per keypoint\n",
    "for i, err in enumerate(mean_per_kp):\n",
    "    print(f\"KP{i:2d}: {err:.2f} px\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65381868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
